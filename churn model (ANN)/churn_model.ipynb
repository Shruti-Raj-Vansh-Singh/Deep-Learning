{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "churn model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ97fbxCEFfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A-Z deep learning \n",
        "# Churn modelling \n",
        "# ANN - a classification model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2QAlR2XETHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1CZbeG5EZRz",
        "colab_type": "code",
        "outputId": "f7b2d92c-aa72-4287-efb2-ed558bb338b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        }
      },
      "source": [
        "! pip install tensorflow==2.1.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (2.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.27.2)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (2.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.18.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.7.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (46.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.21.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn5geA1rEikR",
        "colab_type": "code",
        "outputId": "b76348d3-df07-408b-f038-a0ff3fa2adeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-UBA7KDE9d-",
        "colab_type": "code",
        "outputId": "85f34ff5-14af-4d9c-f525-1880292498de",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4460acda-dc76-4653-bd19-27f53611b6fa\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-4460acda-dc76-4653-bd19-27f53611b6fa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Churn_Modelling.csv to Churn_Modelling (2).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTPJUvpWFFWp",
        "colab_type": "code",
        "outputId": "800e960d-fbee-432b-e2d0-f9e1c1a5c0ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "import io\n",
        "dataset = pd.read_csv(io.BytesIO(uploaded['Churn_Modelling.csv']))\n",
        "dataset.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
              "1          2    15647311      Hill  ...               1       112542.58      0\n",
              "2          3    15619304      Onio  ...               0       113931.57      1\n",
              "3          4    15701354      Boni  ...               0        93826.63      0\n",
              "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MheG2GBob9E",
        "colab_type": "code",
        "outputId": "91cb6c4d-8e9a-43bc-86bd-3c7f8cb37f7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qx5MHB5fdfhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#checking for missing data in the dataset but considers only if the value is not avaiable.\n",
        "print(dataset.isnull().sum())\n",
        "\"\"\"incase the value is 0 then we need to look for another startegy\n",
        "print((dataset[[1,2,3,4,5,6,7,8,9,10,11,12,13]]==0).sum())\n",
        "we can replace this 0 values with Nan as numpy and pandas wont consider them for kinding out the mean, etc\n",
        "dataset.replace(0,np.nan)  would do the work\n",
        "we may also drop the rows with missing values as some algo in machine laenring give an erro if some null value is encountered\n",
        "dataset.dropna(inplace=True)   ths piece of code will remove all the rows with value as null\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HU_5FjVmBZY",
        "colab_type": "code",
        "outputId": "bc4cef4e-5bec-4d47-c7ab-9ebff7d0a7e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "dataset.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10000.00000</td>\n",
              "      <td>1.000000e+04</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.00000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5000.50000</td>\n",
              "      <td>1.569094e+07</td>\n",
              "      <td>650.528800</td>\n",
              "      <td>38.921800</td>\n",
              "      <td>5.012800</td>\n",
              "      <td>76485.889288</td>\n",
              "      <td>1.530200</td>\n",
              "      <td>0.70550</td>\n",
              "      <td>0.515100</td>\n",
              "      <td>100090.239881</td>\n",
              "      <td>0.203700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2886.89568</td>\n",
              "      <td>7.193619e+04</td>\n",
              "      <td>96.653299</td>\n",
              "      <td>10.487806</td>\n",
              "      <td>2.892174</td>\n",
              "      <td>62397.405202</td>\n",
              "      <td>0.581654</td>\n",
              "      <td>0.45584</td>\n",
              "      <td>0.499797</td>\n",
              "      <td>57510.492818</td>\n",
              "      <td>0.402769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.556570e+07</td>\n",
              "      <td>350.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.580000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2500.75000</td>\n",
              "      <td>1.562853e+07</td>\n",
              "      <td>584.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>51002.110000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5000.50000</td>\n",
              "      <td>1.569074e+07</td>\n",
              "      <td>652.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>97198.540000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>100193.915000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7500.25000</td>\n",
              "      <td>1.575323e+07</td>\n",
              "      <td>718.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>127644.240000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>149388.247500</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10000.00000</td>\n",
              "      <td>1.581569e+07</td>\n",
              "      <td>850.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>250898.090000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>199992.480000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         RowNumber    CustomerId  ...  EstimatedSalary        Exited\n",
              "count  10000.00000  1.000000e+04  ...     10000.000000  10000.000000\n",
              "mean    5000.50000  1.569094e+07  ...    100090.239881      0.203700\n",
              "std     2886.89568  7.193619e+04  ...     57510.492818      0.402769\n",
              "min        1.00000  1.556570e+07  ...        11.580000      0.000000\n",
              "25%     2500.75000  1.562853e+07  ...     51002.110000      0.000000\n",
              "50%     5000.50000  1.569074e+07  ...    100193.915000      0.000000\n",
              "75%     7500.25000  1.575323e+07  ...    149388.247500      0.000000\n",
              "max    10000.00000  1.581569e+07  ...    199992.480000      1.000000\n",
              "\n",
              "[8 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EItJ4VqMMucA",
        "colab_type": "code",
        "outputId": "b9fa2b8a-1d63-4e0c-d39c-5365d955330b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           10000 non-null  object \n",
            " 6   Age              10000 non-null  int64  \n",
            " 7   Tenure           10000 non-null  int64  \n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(2), int64(9), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVtZmWT7engA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "impute means using a model to replace the missing values\n",
        "NOT REQUIRED AS THERE ARE NO MSSING VALUES IN THE DATASET\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "\n",
        "we can also use pandas function to impute missing values for each column\n",
        "dataset.fillna(dataset.mean(),  inplace=True)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LHhWm9EBV60",
        "colab_type": "text"
      },
      "source": [
        "#splitting the dataset into input and output\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otgNA83iNYCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X = dataset.iloc[:,[3,-1]].values\n",
        "#y = dataset.iloc[:,13].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwdiOS5wN4S_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = dataset.drop(['RowNumber', 'CustomerId','Surname','Exited'], axis = 1).values\n",
        "Y = dataset['Exited'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng81Y7eHebZa",
        "colab_type": "text"
      },
      "source": [
        "The first step is to check for any missing data that can be seem from the dataset.info command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn08IOKyaN2N",
        "colab_type": "code",
        "outputId": "92e6e603-f5bd-4918-e1d7-6f9998b236cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpEMRMBdiWDi",
        "colab_type": "text"
      },
      "source": [
        "we will be using label encoder to demarcate the different categories of data that we have in a column and then we will use one hot encoder for each category of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_SQeiOmSjkO",
        "colab_type": "code",
        "outputId": "fa1e9cb7-5874-4251-986e-b97a1fb2589e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "X[:2,:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[619, 'France', 'Female', 42, 2, 0.0, 1, 1, 1, 101348.88],\n",
              "       [608, 'Spain', 'Female', 41, 1, 83807.86, 1, 0, 1, 112542.58]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fqHyXRmiKNa",
        "colab_type": "code",
        "outputId": "579e0bf5-7dbd-4ee3-b30c-4bf6ec1357d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "labelencoder_x1 = LabelEncoder()\n",
        "X[:,1] = labelencoder_x1.fit_transform(X[:,1])\n",
        "labelencoder2 = LabelEncoder()\n",
        "X[:,2] = labelencoder2.fit_transform(X[:,2])\n",
        "print(X[:2,:])\n",
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[619 0 0 42 2 0.0 1 1 1 101348.88]\n",
            " [608 2 0 41 1 83807.86 1 0 1 112542.58]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL29v0jFFPP-",
        "colab_type": "code",
        "outputId": "3d0a18ea-5be9-46f2-f776-7ea45ecf03a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "ct = ColumnTransformer(\n",
        "    [('one_hot_encoder', OneHotEncoder(categories='auto'), [1,2])],   # The column numbers to be transformed (here is [0] but can be [0, 1, 3])\n",
        "    remainder='passthrough'                                         # Leave the rest of the columns untouched\n",
        ")\n",
        "X = ct.fit_transform(X)\n",
        "\n",
        "print(X[:2,:])\n",
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0.0 1.0 0.0 619 42 2 0.0 1 1 1 101348.88]\n",
            " [0.0 0.0 1.0 1.0 0.0 608 41 1 83807.86 1 0 1 112542.58]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6I3rQdN--Nu",
        "colab_type": "text"
      },
      "source": [
        "### Standard Scaling\n",
        "Since the vlaues in the various column in X are having a huge range of values we dont want sice certain columns have higher numerical values hence they should have more weightage in deciding what the result of the midel should be"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QpA3JJrFM9x",
        "colab_type": "code",
        "outputId": "f4f9e5ff-54da-496f-f8d6-025fa7512d17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "ss = StandardScaler()\n",
        "X = ss.fit_transform(X)\n",
        "print(X[:5,:])\n",
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.99720391 -0.57873591 -0.57380915  1.09598752 -1.09598752 -0.32622142\n",
            "   0.29351742 -1.04175968 -1.22584767 -0.91158349  0.64609167  0.97024255\n",
            "   0.02188649]\n",
            " [-1.00280393 -0.57873591  1.74273971  1.09598752 -1.09598752 -0.44003595\n",
            "   0.19816383 -1.38753759  0.11735002 -0.91158349 -1.54776799  0.97024255\n",
            "   0.21653375]\n",
            " [ 0.99720391 -0.57873591 -0.57380915  1.09598752 -1.09598752 -1.53679418\n",
            "   0.29351742  1.03290776  1.33305335  2.52705662  0.64609167 -1.03067011\n",
            "   0.2406869 ]\n",
            " [ 0.99720391 -0.57873591 -0.57380915  1.09598752 -1.09598752  0.50152063\n",
            "   0.00745665 -1.38753759 -1.22584767  0.80773656 -1.54776799 -1.03067011\n",
            "  -0.10891792]\n",
            " [-1.00280393 -0.57873591  1.74273971  1.09598752 -1.09598752  2.06388377\n",
            "   0.38887101 -1.04175968  0.7857279  -0.91158349  0.64609167  0.97024255\n",
            "  -0.36527578]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQtvBnDr_eu1",
        "colab_type": "text"
      },
      "source": [
        "#Splitting data into test and training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vudHqJ9B_c7O",
        "colab_type": "code",
        "outputId": "faa4ff9a-bb97-47fd-d8a6-f18f4c9883f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.1,random_state=0)\n",
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9000, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZr5pVViN0BB",
        "colab_type": "text"
      },
      "source": [
        "# Building our Artificial Neural Network\n",
        "We are making our model using the sequential model type. sequential model type help ua building a model layer by layer ie in a sequential manner.\n",
        "we also use the dense layer type this means that all the nodes of the pervious layer are connected with the nodes of the current layer\n",
        "\n",
        "Activation function helps in discovering the non linear relationships."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kw6GNI8_46M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMskaAyAX9vO",
        "colab_type": "text"
      },
      "source": [
        "Till now we have just made the structure for the model.. now we will actually calcluate the weights for layers\n",
        "optimizer is the gradient descent algo we use\n",
        "if we have a binary output we use binary_crossentropy(log cost function), but if the output is having multiple categories then we use softmax function in the layer and the loss function will be categorical_crossentropy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvocx3NiNtoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(6, activation='relu', input_shape=(13,)))       # th first arg is the number of nodes in the layer, input size increases as we used onr=ehotencoder\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))                        #output layer\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20Ab-48CTao1",
        "colab_type": "code",
        "outputId": "cab3d457-ca79-47fa-b83e-a27948f2f637",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train,y_train,batch_size=10, epochs=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 9000 samples\n",
            "Epoch 1/100\n",
            "9000/9000 [==============================] - 2s 179us/sample - loss: 0.4929 - accuracy: 0.7840\n",
            "Epoch 2/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.4341 - accuracy: 0.7980\n",
            "Epoch 3/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.4218 - accuracy: 0.8170\n",
            "Epoch 4/100\n",
            "9000/9000 [==============================] - 1s 155us/sample - loss: 0.4095 - accuracy: 0.8264\n",
            "Epoch 5/100\n",
            "9000/9000 [==============================] - 1s 150us/sample - loss: 0.3881 - accuracy: 0.8376\n",
            "Epoch 6/100\n",
            "9000/9000 [==============================] - 1s 154us/sample - loss: 0.3680 - accuracy: 0.8480\n",
            "Epoch 7/100\n",
            "9000/9000 [==============================] - 1s 152us/sample - loss: 0.3572 - accuracy: 0.8537\n",
            "Epoch 8/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3520 - accuracy: 0.8552\n",
            "Epoch 9/100\n",
            "9000/9000 [==============================] - 1s 153us/sample - loss: 0.3481 - accuracy: 0.8592\n",
            "Epoch 10/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3462 - accuracy: 0.8596\n",
            "Epoch 11/100\n",
            "9000/9000 [==============================] - 1s 153us/sample - loss: 0.3446 - accuracy: 0.8589\n",
            "Epoch 12/100\n",
            "9000/9000 [==============================] - 1s 155us/sample - loss: 0.3425 - accuracy: 0.8599\n",
            "Epoch 13/100\n",
            "9000/9000 [==============================] - 1s 150us/sample - loss: 0.3418 - accuracy: 0.8599\n",
            "Epoch 14/100\n",
            "9000/9000 [==============================] - 1s 152us/sample - loss: 0.3407 - accuracy: 0.8604\n",
            "Epoch 15/100\n",
            "9000/9000 [==============================] - 1s 157us/sample - loss: 0.3398 - accuracy: 0.8612\n",
            "Epoch 16/100\n",
            "9000/9000 [==============================] - 1s 152us/sample - loss: 0.3396 - accuracy: 0.8608\n",
            "Epoch 17/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3388 - accuracy: 0.8589\n",
            "Epoch 18/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3382 - accuracy: 0.8618\n",
            "Epoch 19/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3377 - accuracy: 0.8600\n",
            "Epoch 20/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3374 - accuracy: 0.8592\n",
            "Epoch 21/100\n",
            "9000/9000 [==============================] - 1s 152us/sample - loss: 0.3375 - accuracy: 0.8609\n",
            "Epoch 22/100\n",
            "9000/9000 [==============================] - 1s 152us/sample - loss: 0.3364 - accuracy: 0.8619\n",
            "Epoch 23/100\n",
            "9000/9000 [==============================] - 1s 155us/sample - loss: 0.3372 - accuracy: 0.8614\n",
            "Epoch 24/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3357 - accuracy: 0.8613\n",
            "Epoch 25/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3364 - accuracy: 0.8596\n",
            "Epoch 26/100\n",
            "9000/9000 [==============================] - 1s 152us/sample - loss: 0.3355 - accuracy: 0.8608\n",
            "Epoch 27/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3355 - accuracy: 0.8613\n",
            "Epoch 28/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3355 - accuracy: 0.8623\n",
            "Epoch 29/100\n",
            "9000/9000 [==============================] - 1s 155us/sample - loss: 0.3352 - accuracy: 0.8628\n",
            "Epoch 30/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3343 - accuracy: 0.8622\n",
            "Epoch 31/100\n",
            "9000/9000 [==============================] - 1s 152us/sample - loss: 0.3349 - accuracy: 0.8636\n",
            "Epoch 32/100\n",
            "9000/9000 [==============================] - 1s 152us/sample - loss: 0.3342 - accuracy: 0.8619\n",
            "Epoch 33/100\n",
            "9000/9000 [==============================] - 1s 155us/sample - loss: 0.3347 - accuracy: 0.8628\n",
            "Epoch 34/100\n",
            "9000/9000 [==============================] - 1s 161us/sample - loss: 0.3339 - accuracy: 0.8624\n",
            "Epoch 35/100\n",
            "9000/9000 [==============================] - 1s 158us/sample - loss: 0.3336 - accuracy: 0.8614\n",
            "Epoch 36/100\n",
            "9000/9000 [==============================] - 1s 160us/sample - loss: 0.3338 - accuracy: 0.8631\n",
            "Epoch 37/100\n",
            "9000/9000 [==============================] - 1s 154us/sample - loss: 0.3335 - accuracy: 0.8646\n",
            "Epoch 38/100\n",
            "9000/9000 [==============================] - 1s 152us/sample - loss: 0.3338 - accuracy: 0.8626\n",
            "Epoch 39/100\n",
            "9000/9000 [==============================] - 1s 155us/sample - loss: 0.3337 - accuracy: 0.8629\n",
            "Epoch 40/100\n",
            "9000/9000 [==============================] - 1s 152us/sample - loss: 0.3330 - accuracy: 0.8633\n",
            "Epoch 41/100\n",
            "9000/9000 [==============================] - 1s 153us/sample - loss: 0.3332 - accuracy: 0.8619\n",
            "Epoch 42/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3325 - accuracy: 0.8599\n",
            "Epoch 43/100\n",
            "9000/9000 [==============================] - 1s 154us/sample - loss: 0.3334 - accuracy: 0.8621\n",
            "Epoch 44/100\n",
            "9000/9000 [==============================] - 1s 153us/sample - loss: 0.3322 - accuracy: 0.8627\n",
            "Epoch 45/100\n",
            "9000/9000 [==============================] - 1s 155us/sample - loss: 0.3332 - accuracy: 0.8620\n",
            "Epoch 46/100\n",
            "9000/9000 [==============================] - 1s 154us/sample - loss: 0.3332 - accuracy: 0.8620\n",
            "Epoch 47/100\n",
            "9000/9000 [==============================] - 1s 149us/sample - loss: 0.3328 - accuracy: 0.8637\n",
            "Epoch 48/100\n",
            "9000/9000 [==============================] - 1s 153us/sample - loss: 0.3327 - accuracy: 0.8623\n",
            "Epoch 49/100\n",
            "9000/9000 [==============================] - 1s 153us/sample - loss: 0.3318 - accuracy: 0.8628\n",
            "Epoch 50/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3321 - accuracy: 0.8631\n",
            "Epoch 51/100\n",
            "9000/9000 [==============================] - 1s 152us/sample - loss: 0.3327 - accuracy: 0.8613\n",
            "Epoch 52/100\n",
            "9000/9000 [==============================] - 1s 152us/sample - loss: 0.3321 - accuracy: 0.8623\n",
            "Epoch 53/100\n",
            "9000/9000 [==============================] - 1s 153us/sample - loss: 0.3316 - accuracy: 0.8630\n",
            "Epoch 54/100\n",
            "9000/9000 [==============================] - 1s 155us/sample - loss: 0.3325 - accuracy: 0.8620\n",
            "Epoch 55/100\n",
            "9000/9000 [==============================] - 1s 152us/sample - loss: 0.3316 - accuracy: 0.8629\n",
            "Epoch 56/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3317 - accuracy: 0.8640\n",
            "Epoch 57/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3320 - accuracy: 0.8606\n",
            "Epoch 58/100\n",
            "9000/9000 [==============================] - 1s 150us/sample - loss: 0.3322 - accuracy: 0.8617\n",
            "Epoch 59/100\n",
            "9000/9000 [==============================] - 1s 152us/sample - loss: 0.3317 - accuracy: 0.8627\n",
            "Epoch 60/100\n",
            "9000/9000 [==============================] - 1s 156us/sample - loss: 0.3320 - accuracy: 0.8614\n",
            "Epoch 61/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3317 - accuracy: 0.8618\n",
            "Epoch 62/100\n",
            "9000/9000 [==============================] - 1s 154us/sample - loss: 0.3321 - accuracy: 0.8640\n",
            "Epoch 63/100\n",
            "9000/9000 [==============================] - 1s 150us/sample - loss: 0.3316 - accuracy: 0.8624\n",
            "Epoch 64/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3314 - accuracy: 0.8634\n",
            "Epoch 65/100\n",
            "9000/9000 [==============================] - 1s 155us/sample - loss: 0.3310 - accuracy: 0.8638\n",
            "Epoch 66/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3313 - accuracy: 0.8626\n",
            "Epoch 67/100\n",
            "9000/9000 [==============================] - 1s 152us/sample - loss: 0.3311 - accuracy: 0.8642\n",
            "Epoch 68/100\n",
            "9000/9000 [==============================] - 1s 156us/sample - loss: 0.3312 - accuracy: 0.8639\n",
            "Epoch 69/100\n",
            "9000/9000 [==============================] - 1s 153us/sample - loss: 0.3310 - accuracy: 0.8636\n",
            "Epoch 70/100\n",
            "9000/9000 [==============================] - 1s 153us/sample - loss: 0.3307 - accuracy: 0.8642\n",
            "Epoch 71/100\n",
            "9000/9000 [==============================] - 1s 154us/sample - loss: 0.3309 - accuracy: 0.8632\n",
            "Epoch 72/100\n",
            "9000/9000 [==============================] - 1s 153us/sample - loss: 0.3302 - accuracy: 0.8651\n",
            "Epoch 73/100\n",
            "9000/9000 [==============================] - 1s 152us/sample - loss: 0.3311 - accuracy: 0.8640\n",
            "Epoch 74/100\n",
            "9000/9000 [==============================] - 1s 153us/sample - loss: 0.3304 - accuracy: 0.8650\n",
            "Epoch 75/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3303 - accuracy: 0.8637\n",
            "Epoch 76/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3300 - accuracy: 0.8633\n",
            "Epoch 77/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3304 - accuracy: 0.8624\n",
            "Epoch 78/100\n",
            "9000/9000 [==============================] - 1s 154us/sample - loss: 0.3302 - accuracy: 0.8637\n",
            "Epoch 79/100\n",
            "9000/9000 [==============================] - 1s 155us/sample - loss: 0.3298 - accuracy: 0.8642\n",
            "Epoch 80/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3305 - accuracy: 0.8628\n",
            "Epoch 81/100\n",
            "9000/9000 [==============================] - 1s 152us/sample - loss: 0.3298 - accuracy: 0.8642\n",
            "Epoch 82/100\n",
            "9000/9000 [==============================] - 1s 155us/sample - loss: 0.3298 - accuracy: 0.8639\n",
            "Epoch 83/100\n",
            "9000/9000 [==============================] - 1s 149us/sample - loss: 0.3305 - accuracy: 0.8648\n",
            "Epoch 84/100\n",
            "9000/9000 [==============================] - 1s 152us/sample - loss: 0.3299 - accuracy: 0.8646\n",
            "Epoch 85/100\n",
            "9000/9000 [==============================] - 1s 152us/sample - loss: 0.3303 - accuracy: 0.8632\n",
            "Epoch 86/100\n",
            "9000/9000 [==============================] - 1s 152us/sample - loss: 0.3293 - accuracy: 0.8643\n",
            "Epoch 87/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3299 - accuracy: 0.8626\n",
            "Epoch 88/100\n",
            "9000/9000 [==============================] - 1s 153us/sample - loss: 0.3297 - accuracy: 0.8640\n",
            "Epoch 89/100\n",
            "9000/9000 [==============================] - 1s 153us/sample - loss: 0.3301 - accuracy: 0.8641\n",
            "Epoch 90/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3294 - accuracy: 0.8637\n",
            "Epoch 91/100\n",
            "9000/9000 [==============================] - 1s 150us/sample - loss: 0.3302 - accuracy: 0.8649\n",
            "Epoch 92/100\n",
            "9000/9000 [==============================] - 1s 152us/sample - loss: 0.3294 - accuracy: 0.8639\n",
            "Epoch 93/100\n",
            "9000/9000 [==============================] - 1s 153us/sample - loss: 0.3290 - accuracy: 0.8640\n",
            "Epoch 94/100\n",
            "9000/9000 [==============================] - 1s 154us/sample - loss: 0.3300 - accuracy: 0.8648\n",
            "Epoch 95/100\n",
            "9000/9000 [==============================] - 1s 152us/sample - loss: 0.3294 - accuracy: 0.8644\n",
            "Epoch 96/100\n",
            "9000/9000 [==============================] - 1s 155us/sample - loss: 0.3291 - accuracy: 0.8642\n",
            "Epoch 97/100\n",
            "9000/9000 [==============================] - 1s 153us/sample - loss: 0.3302 - accuracy: 0.8634\n",
            "Epoch 98/100\n",
            "9000/9000 [==============================] - 1s 151us/sample - loss: 0.3292 - accuracy: 0.8653\n",
            "Epoch 99/100\n",
            "9000/9000 [==============================] - 1s 154us/sample - loss: 0.3294 - accuracy: 0.8667\n",
            "Epoch 100/100\n",
            "9000/9000 [==============================] - 1s 155us/sample - loss: 0.3299 - accuracy: 0.8643\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f515ce53080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vey5uqyydkAF",
        "colab_type": "text"
      },
      "source": [
        "the accuracy of the training set is 85.78%\n",
        "now we will check the accuracy for the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fyxd1XzyZeuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sqtRQG3eeLT",
        "colab_type": "text"
      },
      "source": [
        "evaluating the model for its accuracy and loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIx0VkXwecPG",
        "colab_type": "code",
        "outputId": "5af11f10-fe1e-411d-ab4d-32ae0c7551a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "loss, accuracy = model.evaluate(X_test,y_test,verbose=1)\n",
        "print(\"test accuracy=\",accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 101us/sample - loss: 0.3277 - accuracy: 0.8600\n",
            "test accuracy= 0.86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G7yiF0hfj4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}